{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d1b52fa-23dd-4dcc-9992-aff00035dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO, NAS\n",
    "import sys # to access the system\n",
    "import cv2\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import super_gradients\n",
    "import supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f456edff-9b36-4860-8bf2-f076b20dd67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path2img(img_num, dbpath):\n",
    "    img_pad = str(img_num).zfill(6)\n",
    "    return f\"{dbpath}\\\\frame_{img_pad}.PNG\"\n",
    "\n",
    "def load_annotations(annotation_path: str):\n",
    "    \"\"\"\n",
    "    annotation_path: str = r\"D:\\Dataset\\FishDetection\\Annotation\\task_fish_detection-2024_02_05_18_52_05-cvat for video 1.1\"\n",
    "    Give full path to the CVAT formatted folder which contains annotations.xml\n",
    "    \"\"\"\n",
    "    path=f\"{annotation_path}\\\\annotations.xml\"\n",
    "    with open(path, 'r') as f:\n",
    "        data = f.read()\n",
    "    Bs_data = BeautifulSoup(data, \"xml\")\n",
    "    metadata = Bs_data.find('meta').find(\"task\").find(\"segments\")\n",
    "    # Get the annotations frame count\n",
    "    start_frame = int(metadata.find(\"start\").text)\n",
    "    stop_frame = int(metadata.find(\"stop\").text)\n",
    "    # The annotations is within track property\n",
    "    box_annotations = Bs_data.find_all('track')\n",
    "    # Check if there are any annotations of fish, else return empty box annotations\n",
    "    if box_annotations:\n",
    "        # Only get box elements\n",
    "        map_frame_to_index = {}\n",
    "        all_boxes = box_annotations[0].find_all('box')\n",
    "        for i in range(1, len(box_annotations)):\n",
    "            all_boxes += box_annotations[i].find_all('box')\n",
    "        for j, box in enumerate(all_boxes):\n",
    "            #print(str(box[\"frame\"]))\n",
    "            if box[\"frame\"] in map_frame_to_index:\n",
    "                map_frame_to_index[box[\"frame\"]] += [j]\n",
    "            else:\n",
    "                map_frame_to_index[box[\"frame\"]] = [j]\n",
    "        return all_boxes, map_frame_to_index, (start_frame, stop_frame)\n",
    "    return \"\", {}, (start_frame, stop_frame)\n",
    "\n",
    "def convert_png_to_video(input_path: str, output_path: str, fps: int = 30, crf: int = 23):\n",
    "    \"\"\"\n",
    "    Convert a sequence of PNG files to a video using ffmpeg.\n",
    "    # Example usage:\n",
    "    # convert_png_to_video(\n",
    "    #     input_path=\"path/to/png/folder\",\n",
    "    #     output_path=\"output_video.mp4\",\n",
    "    #     fps=30,\n",
    "    #     crf=23\n",
    "    # )\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to folder containing PNG files (should end with %d.png format)\n",
    "        output_path: Output video file path (.mp4)\n",
    "        fps: Frames per second (default: 30)\n",
    "        crf: Constant Rate Factor - video quality (18-28, lower is better quality)\n",
    "    \"\"\"\n",
    "    ffmpeg_cmd = [\n",
    "        'ffmpeg',\n",
    "        '-framerate', str(fps),\n",
    "        '-i', os.path.join(input_path, 'frame_%06d.PNG'),  # Assumes files are named 1.png, 2.png, etc.\n",
    "        '-c:v', 'libx264',\n",
    "        '-crf', str(crf),\n",
    "        '-pix_fmt', 'yuv420p',\n",
    "        output_path\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(ffmpeg_cmd, check=True)\n",
    "        print(f\"Video created successfully: {output_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error creating video: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#img = cv2.imread(\"sheep.png\", cv2.IMREAD_ANYCOLOR)\n",
    "DBPATH = r\"D:\\Dataset\\FishDetection\\Annotation\\task_fish_detection-2024_01_28_18_07_53-cvat for video 1.1\\images\"\n",
    "ANNOTATIONS= r\"D:\\Dataset\\FishDetection\\Annotation\\task_fish_detection-2024_01_28_18_07_53-cvat for video 1.1\"\n",
    "DBROOT= r\"D:\\Dataset\\FishDetection\\Annotation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f631bf0f-62a2-42ef-83d8-f066f50e2dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "013850ac-a4a1-4f01-9c8b-092cdbf25c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a COCO-pretrained YOLO11n model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "# Check https://docs.ultralytics.com/models/ for other models\n",
    "\n",
    "# Example: Train the model on the COCO8 example dataset for 100 epochs\n",
    "results = model.train(data=\"coco8.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "12ba8b10-10ea-4290-b3fe-e8ccc7fa1256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directories = os.listdir(DBROOT)\n",
    "for i in range(5, 20, 1):\n",
    "    convert_png_to_video(f\"{DBROOT}\\{directories[1]}\\images\", f\"test{i}.mp4\")\n",
    "        #print(f\"{DBROOT}\\{directories[i]}\")\n",
    "        #continueNext = showVideo(f\"{DBROOT}\\{directories[i]}\",windowID, skip_empty=True)\n",
    "    #p = path2img(i, f\"{DBROOT}\\{directories[i]}\"+\"\\images\")\n",
    "    #print(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e09e7-4e25-4f65-b585-6e5f397b0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_png_to_video(r\"D:\\Dataset\\FishDetection\\Annotation\\task_20230716080335_20230716080344_3.mp4_dataset_2024_02_26_06_54_04_cvat for video 1.1\\images\", \"fish.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1137d16e-8739-4b69-aa62-026f93f8d8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\alf\\Documents\\programming\\python\\IMT4392\\Project\\datasets\\fish.v1-fish_imagesize_320.yolov11\\val\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 19/19 [00:06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17435146167556403"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation\n",
    "#rootpath = r\"D:\\Dataset\\FishDetection2Yolo\\data.yaml\"\n",
    "rootpath = r\"C:\\Users\\alf\\Documents\\programming\\python\\IMT4392\\Project\\datasets\\fish.v1-fish_imagesize_320.yolov11\\data.yaml\"\n",
    "#FishDetection\\Annotation\"\n",
    "model = YOLO(r\"./runs/detect/train15/weights/best.pt\")\n",
    "metrics = model.val(data=rootpath,save_json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "18d75912-f9d9-4946-8c1f-308ea4c79148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17435146167556403"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.33502453644448804"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.16982630220761663"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([    0.17435])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(metrics.box.map)  # mAP50-95\n",
    "display(metrics.box.map50)  # mAP50\n",
    "display(metrics.box.map75)  # mAP75\n",
    "display(metrics.box.maps)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bd436fe-1c93-493b-8c0f-4b0358f9f472",
   "metadata": {},
   "source": [
    "# Validation from Yolo11n trained on Anadrom/Nordavin dataset\n",
    "## Nordavin androm\n",
    "0.3971922007989249 -mAP50-95\n",
    "0.7130188014244321 - mAP50\n",
    "0.39601072371740353 - MAP75\n",
    "array([    0.39719])\n",
    "## Deepfish\n",
    "0.17435146167556403 - mAP50-95\n",
    "0.33502453644448804 - mAP50\n",
    "0.16982630220761663 - mAP75\n",
    "array([    0.17435])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62eb93f-7919-4f2d-b225-57b3cbe78ded",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model(r\"C:\\Users\\alf\\Videos\\WokeTutorial.mp4\",save=True, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cb801-a02d-4f29-8eff-dceaa603c03a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = YOLO(\"yolov10n.pt\")\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "results = model(\"fish.mp4\",save=True, show=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
